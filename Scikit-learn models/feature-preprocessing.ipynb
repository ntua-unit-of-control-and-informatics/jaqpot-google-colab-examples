{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089a0a6a",
   "metadata": {},
   "source": [
    "# Feature Preprocessing\n",
    "\n",
    "## Using Multiple Featurizers\n",
    "\n",
    "In the first script, we initialize two molecular descriptor calculators from JaqpotPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de54bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaqpotpy.descriptors import RDKitDescriptors, MACCSKeysFingerprint\n",
    "\n",
    "featurizers = [RDKitDescriptors(), MACCSKeysFingerprint()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0b7f5",
   "metadata": {},
   "source": [
    "We then pass this list of featurizers to the `JaqpotpyDataset` object when creating the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021f420",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'JaqpotpyDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mJaqpotpyDataset\u001b[49m(\n\u001b[1;32m      2\u001b[0m     df\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m      3\u001b[0m     x_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcat_col\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m     y_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     smiles_cols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmiles\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     featurizer\u001b[38;5;241m=\u001b[39mfeaturizers,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'JaqpotpyDataset' is not defined"
     ]
    }
   ],
   "source": [
    "data = \n",
    "\n",
    "train_dataset = JaqpotpyDataset(\n",
    "    df=data,\n",
    "    x_cols=[\"cat_col\", \"temperature\"],\n",
    "    y_cols=[\"activity\"],\n",
    "    smiles_cols=[\"smiles\"],\n",
    "    task=\"regression\",\n",
    "    featurizer=featurizers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb54c6f3",
   "metadata": {},
   "source": [
    "By providing a list of featurizers, the dataset will generate both RDKit descriptors and MACCS keys fingerprints for the SMILES data, resulting in a more comprehensive set of molecular features.\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "In the second script, we demonstrate the use of feature selection. After creating the `JaqpotpyDataset` object, we apply a feature selection technique using the `select_features()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use VarianceThreshold to select features with a minimum variance of 0.1\n",
    "FeatureSelector = VarianceThreshold(threshold=0.1)\n",
    "train_dataset.select_features(\n",
    "    FeatureSelector,\n",
    "    ExcludeColumns=[\"cat_col\"],  # Explicitly exclude the categorical variable\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b2afd",
   "metadata": {},
   "source": [
    "This will apply the VarianceThreshold feature selector to the dataset, excluding the \"cat_col\" variable, which is a categorical feature that cannot be included in the selection process.\n",
    "\n",
    "Alternatively, you can directly select specific columns by name using the `SelectColumns` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = [\n",
    "    \"temperature\",\n",
    "    \"MaxAbsEStateIndex\",\n",
    "    \"MaxEStateIndex\",\n",
    "    \"MinAbsEStateIndex\",\n",
    "    \"MinEStateIndex\",\n",
    "    \"SPS\",\n",
    "    \"MolWt\",\n",
    "    \"HeavyAtomMolWt\",\n",
    "]\n",
    "train_dataset.select_features(SelectColumns=myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc5124",
   "metadata": {},
   "source": [
    "This method allows you to manually choose the features you want to include in the model, which can be useful if you have domain knowledge about the most relevant variables.\n",
    "\n",
    "## Feature Preprocessing\n",
    "\n",
    "In the first script, we define a preprocessing pipeline for the feature columns and the target column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for the feature columns\n",
    "double_preprocessing = [\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"OneHotEncoder\", OneHotEncoder(), [\"cat_col\"]),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        force_int_remainder_cols=False,\n",
    "    ),\n",
    "    StandardScaler(),  # Standard scaling for numerical features after encoding\n",
    "]\n",
    "\n",
    "# Preprocessing for the target column\n",
    "single_preprocessing = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd9fe3",
   "metadata": {},
   "source": [
    "The `double_preprocessing` pipeline first applies OneHotEncoder to the categorical \"cat_col\" feature, then applies StandardScaler to the numerical features (including the encoded categorical variable).\n",
    "\n",
    "The `single_preprocessing` pipeline applies MinMaxScaler to the target variable \"activity\".\n",
    "\n",
    "We then pass these preprocessing pipelines to the `SklearnModel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaqpot_model = SklearnModel(\n",
    "    dataset=train_dataset,\n",
    "    model=model,\n",
    "    preprocess_x=double_preprocessing,\n",
    "    preprocess_y=single_preprocessing,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e1692f",
   "metadata": {},
   "source": [
    "This ensures that the feature and target variables are properly preprocessed before being used to train the machine learning model.\n",
    "\n",
    "By using multiple featurizers, feature selection, and feature preprocessing, you can create more robust and effective machine learning models with JaqpotPy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
