{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645bd5e1",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ntua-unit-of-control-and-informatics/jaqpot-google-collab-examples/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea20028",
   "metadata": {},
   "source": [
    "# Feature Preprocessing\n",
    "\n",
    "## Using Multiple Featurizers\n",
    "\n",
    "This guide is about using multiple featurizers and performing feature selection.\n",
    "\n",
    "First, we import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1063a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from jaqpotpy.models import SklearnModel\n",
    "from jaqpotpy.datasets import JaqpotpyDataset\n",
    "from jaqpotpy.descriptors import RDKitDescriptors, MACCSKeysFingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833cbd51",
   "metadata": {},
   "source": [
    "Create a dataframe with SMILES strings, a categorical variable, temperature, and activity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488d3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://github.com/ntua-unit-of-control-and-informatics/jaqpot-google-colab-examples/raw/doc/JAQPOT-425/Sklearn_jupyter_examples/datasets/regression_smiles_categorical.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e65fe5",
   "metadata": {},
   "source": [
    "Define a list of desired featurizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80fbd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaqpotpy.descriptors import RDKitDescriptors, MACCSKeysFingerprint\n",
    "featurizers = [RDKitDescriptors(), MACCSKeysFingerprint()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeff909",
   "metadata": {},
   "source": [
    "We then pass this list of featurizers to the `JaqpotpyDataset` object when creating the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8eeed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JaqpotpyDataset(\n",
    "    df=data,\n",
    "    x_cols=[\"cat_col\", \"temperature\"],\n",
    "    y_cols=[\"activity\"],\n",
    "    smiles_cols=[\"smiles\"],\n",
    "    task=\"regression\",\n",
    "    featurizer=featurizers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff1dda",
   "metadata": {},
   "source": [
    "By providing a list of featurizers, the dataset will generate both RDKit descriptors and MACCS keys fingerprints for the SMILES data, resulting in a more comprehensive set of molecular features.\n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "In the second script, we demonstrate the use of feature selection. After creating the `JaqpotpyDataset` object, we apply a feature selection technique using the `select_features()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e59ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use VarianceThreshold to select features with a minimum variance of 0.1\n",
    "FeatureSelector = VarianceThreshold(threshold=0.1)\n",
    "train_dataset.select_features(\n",
    "    FeatureSelector,\n",
    "    ExcludeColumns=[\"cat_col\"],  # Explicitly exclude the categorical variable\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040916f",
   "metadata": {},
   "source": [
    "This will apply the VarianceThreshold feature selector to the dataset, excluding the \"cat_col\" variable, which is a categorical feature that cannot be included in the selection process.\n",
    "\n",
    "Alternatively, you can directly select specific columns by name using the `SelectColumns` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c678d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = [\n",
    "    \"temperature\",\n",
    "    \"cat_col\",\n",
    "    \"MaxAbsEStateIndex\",\n",
    "    \"MaxEStateIndex\",\n",
    "    \"MinAbsEStateIndex\",\n",
    "    \"MinEStateIndex\",\n",
    "    \"SPS\",\n",
    "    \"MolWt\",\n",
    "    \"HeavyAtomMolWt\",\n",
    "]\n",
    "train_dataset.select_features(SelectColumns=myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71441382",
   "metadata": {},
   "source": [
    "This method allows you to manually choose the features you want to include in the model, which can be useful if you have domain knowledge about the most relevant variables.\n",
    "\n",
    "## Feature Preprocessing\n",
    "\n",
    "In the first script, we define a preprocessing pipeline for the feature columns and the target column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4ea262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for the feature columns\n",
    "double_preprocessing = [\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"OneHotEncoder\", OneHotEncoder(), [\"cat_col\"]),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        force_int_remainder_cols=False,\n",
    "    ),\n",
    "    StandardScaler(),  # Standard scaling for numerical features after encoding\n",
    "]\n",
    "\n",
    "# Preprocessing for the target column\n",
    "single_preprocessing = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d84fe7",
   "metadata": {},
   "source": [
    "The `double_preprocessing` pipeline first applies OneHotEncoder to the categorical \"cat_col\" feature, then applies StandardScaler to the numerical features (including the encoded categorical variable).\n",
    "\n",
    "The `single_preprocessing` pipeline applies MinMaxScaler to the target variable \"activity\".\n",
    "\n",
    "We then pass these preprocessing pipelines to the `SklearnModel` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c43c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness-of-fit metrics on training set:\n",
      "{'r2': 0.9376826862159472, 'mae': 0.9549999999999983, 'rmse': 1.3120060975468062}\n"
     ]
    }
   ],
   "source": [
    "jaqpot_model = SklearnModel(\n",
    "    dataset=train_dataset,\n",
    "    model=RandomForestRegressor(random_state=42),\n",
    "    preprocess_x=double_preprocessing,\n",
    "    preprocess_y=single_preprocessing,\n",
    ")\n",
    "jaqpot_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622bc881",
   "metadata": {},
   "source": [
    "This ensures that the feature and target variables are properly preprocessed before being used to train the machine learning model.\n",
    "\n",
    "By using multiple featurizers, feature selection, and feature preprocessing, you can create more robust and effective machine learning models with JaqpotPy."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
